---
title: "深度搜索"
description: "在ADP复现深度搜索智能体的实践经验"
enableComments: true
author: "Steven Lynn"
github_username: "stvlynn"
x_username: "Stv_Lynn"
demo_url: https://adp-deepresearch.vercel.app
---

⬇️ 先睹为快

<Callout title="使用方法">输入研究主题，例如"腾讯云AI"，即可生成一份结构化的研究报告。</Callout>

<iframe
  src="https://adp-deepresearch.vercel.app/" 
  style={{ width: '100%', height: '600px', border: '0' }}
  allow="clipboard-write *; microphone; camera"
></iframe>

## 前言

最近在腾讯云智能体开发平台（ADP）上尝试构建了一个深度搜索智能体，这个项目让我对低代码工作流编排有了全新的认识。今天想和大家分享一下在这个过程中的实践经验，希望能给正在探索AI Agent开发的朋友们一些启发。

## 项目背景

深度搜索不同于简单的关键词检索，它需要对用户的研究主题进行多维度拆解，通过递进式的信息收集和智能汇总，最终生成一份结构化的研究报告。这种复杂的任务流程，正好适合用工作流编排的方式来实现。

## 整体架构设计

### 工作流层级关系

整个系统采用了多层嵌套的工作流架构，每一层都有明确的职责分工：

<Mermaid
  chart={`
graph TD
    subgraph "主工作流：深度搜索主工作流"
        A1[开始] --> A2[获取研究主题]
        A2 --> A3[显示主题确认]
        A3 --> A4[生成4个子主题]
        A4 --> A5[显示子主题]
        A5 --> A6{执行确认}
        A6 -->|确认| A7[批处理调用研究执行]
        A6 -->|取消| A8[结束]
        A7 --> A9[等待提示]
        A9 --> A10[最终报告汇总]
        A10 --> A11[显示报告]
        A11 --> A12{生成PDF?}
        A12 -->|是| A13[调用PDF生成工作流]
        A12 -->|否| A14[结束]
    end
    
    A7 -.->|批处理调用| B1
    A13 -.->|工作流引用| C1
    
    subgraph "第二层-子工作流：研究执行"
        B1[接收主题和子主题] --> B2[生成研究步骤]
        B2 --> B3[循环执行]
        B3 --> B4[调用研究执行子工作流]
        B4 --> B5[汇总生成子主题报告]
        B5 --> B6[返回主流程]
    end
    
    subgraph "第二层-子工作流：PDF生成"
        C1[接收内容] --> C2[生成HTML5]
        C2 --> C3[部署EdgeOne]
        C3 --> C4[转换PDF]
        C4 --> C5[提取URL]
        C5 --> C6[返回URL]
    end
    
    B4 -.->|循环调用| D1
    
    subgraph "第三层-基础工作流：研究执行子工作流"
        D1[接收步骤] --> D2{工具路由}
        D2 -->|搜索引擎| D3[生成关键词]
        D2 -->|ArXiv| D4[生成ArXiv关键词]
        D3 --> D5[批处理关键词搜索]
        D4 --> D6[批处理论文搜索]
        D5 --> D7[变量聚合]
        D6 --> D7
        D7 --> D8[生成步骤报告]
    end
    
    D5 -.->|批处理| E1
    D6 -.->|批处理| F1
    
    subgraph "第三层-基础工作流：关键词搜索"
        E1[混元AI搜索] --> E2[返回搜索结果]
    end
    
    subgraph "第三层-基础工作流：论文搜索"
        F1[ArXiv API搜索] --> F2[返回论文结果]
    end
    
    style A1 fill:#ff6666
    style A8 fill:#ff6666
    style A14 fill:#ff6666
    
    classDef mainFlow fill:#fff4e6,stroke:#ff9800,stroke-width:2px
    classDef subFlow fill:#e3f2fd,stroke:#2196f3,stroke-width:2px
    classDef baseFlow fill:#f1f8e9,stroke:#689f38,stroke-width:2px
    classDef decision fill:#fff9c4,stroke:#fbc02d,stroke-width:2px
    
    class A1,A2,A3,A4,A5,A7,A9,A10,A11,A13 mainFlow
    class B1,B2,B3,B4,B5,B6,C1,C2,C3,C4,C5,C6 subFlow
    class D1,D3,D4,D5,D6,D7,D8,E1,E2,F1,F2 baseFlow
    class A6,A12,D2 decision
    `}
    />

## 核心流程实现

### 1. 主题拆解与子主题生成

用户输入研究主题后，系统首先会进行智能拆解：

```
用户输入 -> 主题确认 -> 生成4个研究子主题 -> 子主题确认
```

这里有个关键的设计点：系统会生成带有探索性的子主题，而不是简单的关键词拆分。比如研究"人工智能"，系统可能会生成：
- 技术发展现状与趋势
- 实际应用案例分析
- 伦理与社会影响
- 未来挑战与机遇

**主题收集**

| 参数名称 | 参数类型 | 参数描述 |
| --- | --- | --- |
| 研究主题 | string | 需要进行研究的主题，用一句话概括即可 |

![image.png](https://s2.loli.net/2025/09/25/zR3kYl2I9hLXuTM.png)

**子主题收集**

| 参数名称 | 参数类型 | 参数描述 |
| --- | --- | --- |
| 研究子主题 | array[string]| 四个独立的研究子主题。在录入的时候需要把研究主题的内容也包含进来形成一个具有主谓宾完整的主题。 |

![image.png](https://s2.loli.net/2025/09/26/cX7obxeC2IFpmZq.png)

### 2. 并行批处理机制

<Mermaid
  chart="
graph LR;
    A[子主题列表] --> B[批处理节点];
    B --> C1[子主题1研究];
    B --> C2[子主题2研究];
    B --> C3[子主题3研究];
    C1 --> D[结果汇总];
    C2 --> D;
    C3 --> D;"
/>

系统采用批处理节点来并行执行子主题研究，最大并行数设置为3。这个数字是经过权衡的：
- 太少会导致执行时间过长
- 太多可能触发API并发限制

![image.png](https://s2.loli.net/2025/09/26/JloqRGFp4Si2rfO.png)

### 3. 智能工具路由

研究执行时，系统会根据步骤内容智能选择搜索工具：

<Mermaid
  chart="
graph TD;
    A[研究步骤] --> B{工具路由判断};
    B -->|学术内容| C[ArXiv论文搜索];
    B -->|一般信息| D[混元AI搜索];
    B -->|默认| E[通用搜索];
    C --> F[关键词生成];
    D --> F;
    E --> F;
    F --> G[批量搜索];
    G --> H[结果汇总];"
/>

这种动态路由机制让系统能够针对不同类型的信息需求，选择最合适的搜索渠道。

![image.png](https://s2.loli.net/2025/09/26/ZNGPaXy1p3xRAfz.png)

## 关键技术要点

### 1. 模型选择策略

不同环节使用不同的模型是优化成本和效果的关键：

| 任务类型 | 选用模型 | 原因 |
|---------|---------|------|
| 子主题生成 | DeepSeek V3 | 创造性强，理解深度好 |
| 步骤规划 | CS-Normal-70B | 逻辑性强，成本适中 |
| 最终汇总 | DeepSeek R1 | 综合能力强，输出质量高 |
| 工具路由 | 混元模型 | 响应快，判断准确 |

### 2. 变量聚合技巧

在处理多路径返回的数据时，变量聚合节点发挥了重要作用：

```javascript
// 聚合配置示例
{
  "result": [搜索结果数组, 论文结果数组],
  "keyword": [搜索关键词, ArXiv关键词]
}
```

![image.png](https://s2.loli.net/2025/09/26/lZexcCS6Ujd98TX.png)

### 3. 用户体验优化

#### 进度提示
在各个关键节点设置了等待消息：
- "正在为xxx生成研究步骤..."
- "正在生成最终报告，预计需要1分钟..."

#### 交互确认
在执行耗时操作前增加确认环节：
- 显示预计执行时间
- 允许用户取消操作

![image.png](https://s2.loli.net/2025/09/26/vgVkEYX2ze9P6hW.png)

## 输出形式创新

### PDF生成流程

系统不仅能生成文本报告，还支持PDF导出：

<Mermaid
  chart="
graph LR;
    A[Markdown报告] --> B[HTML5转换];
    B --> C[部署到EdgeOne];
    C --> D[在线预览链接];
    D --> E[PDF转换服务];
    E --> F[PDF下载链接];"
/>

这个流程的巧妙之处在于利用了EdgeOne的静态托管能力，实现了报告的在线分享。

![image.png](https://s2.loli.net/2025/09/26/48AujbOWqYamkfC.png)


## 总结与展望

未来可以探索的方向：
1. **知识图谱集成**：构建研究主题之间的关联
2. **多模态支持**：加入图片、视频等内容的分析
3. **协作研究**：支持多人共同研究同一主题
4. **增量更新**：支持对已有报告的更新和补充


---

希望这篇分享能给正在探索AI Agent开发的你一些启发。低代码不意味着低能力，关键在于如何巧妙地编排和组合。期待看到更多有创意的智能体应用！

如果你在实践中遇到问题，欢迎在评论区交流讨论。